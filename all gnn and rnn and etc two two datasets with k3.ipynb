{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf683d3-4231-43b7-abba-d185cf4c71ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB  # Importing MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import torch\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define your GCN model (placeholder)\n",
    "class GCNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCNModel, self).__init__()\n",
    "        self.gc = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.gc(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Define your RNN model\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.rnn = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convert input to float if it's LongTensor (assuming it should be FloatTensor)\n",
    "        if x.dtype != torch.float32:\n",
    "            x = x.to(torch.float32)\n",
    "        \n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc(out[:, -1, :])  # Use the last hidden state\n",
    "        return F.log_softmax(out, dim=1)\n",
    "\n",
    "def load_and_preprocess_data(data_path):\n",
    "    bug_reports = pd.read_csv(data_path)\n",
    "\n",
    "    bug_reports['creation_date'] = pd.to_datetime(bug_reports['creation_date'], errors='coerce')\n",
    "    bug_reports['resolution_date'] = pd.to_datetime(bug_reports['resolution_date'])\n",
    "    bug_reports['bug_fix_time'] = (bug_reports['resolution_date'] - bug_reports['creation_date']).dt.days\n",
    "    bug_reports = bug_reports.dropna(subset=['bug_fix_time', 'short_description'])\n",
    "\n",
    "    threshold = 10\n",
    "    bug_reports['bug_class'] = np.where(bug_reports['bug_fix_time'] <= threshold, 'short-lived', 'long-lived')\n",
    "\n",
    "    return bug_reports\n",
    "\n",
    "def extract_tfidf_features(bug_reports):\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=128, stop_words='english')\n",
    "    tfidf_features = tfidf_vectorizer.fit_transform(bug_reports['short_description']).toarray()\n",
    "\n",
    "    return tfidf_features\n",
    "\n",
    "def extract_distilbert_features(bug_reports):\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "    def extract_distilbert_feature(text):\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
    "        outputs = model(**inputs)\n",
    "        return outputs.last_hidden_state.mean(dim=1).squeeze().detach().numpy()\n",
    "\n",
    "    distilbert_features = np.array(bug_reports['short_description'].apply(extract_distilbert_feature).tolist())\n",
    "    distilbert_features = torch.tensor(distilbert_features)\n",
    "\n",
    "    return distilbert_features\n",
    "\n",
    "def extract_gcn_features(bug_reports):\n",
    "    input_dim = 256  # Placeholder for input dimension\n",
    "    gcn_features = torch.randn(len(bug_reports), input_dim)  # Dummy feature vector\n",
    "    \n",
    "    return gcn_features\n",
    "\n",
    "def extract_rnn_features(bug_reports):\n",
    "    # Example function to extract RNN features (assuming `padded_texts` is available)\n",
    "    # Modify according to your actual data structure\n",
    "    padded_texts = torch.randn(len(bug_reports), 10, 50)  # Example padded_texts, adjust dimensions\n",
    "\n",
    "    # Initialize RNN model\n",
    "    rnn_model = RNNModel(input_dim=padded_texts.shape[-1], hidden_dim=128, output_dim=2)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        rnn_features = rnn_model(padded_texts)\n",
    "\n",
    "    return rnn_features\n",
    "\n",
    "def train_and_evaluate_classifier(X_train, X_test, y_train, y_test, classifier, feature_type):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    predictions = classifier.predict(X_test)\n",
    "\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    balanced_accuracy = np.mean([cm[i, i] / np.sum(cm[i]) for i in range(len(np.unique(y_test)))])\n",
    "    \n",
    "    acc_score = accuracy_score(y_test, predictions)\n",
    "    class_report = classification_report(y_test, predictions, output_dict=True)\n",
    "    \n",
    "    # Extract precision, recall, f1-score for each class from classification report\n",
    "    precision = class_report['weighted avg']['precision']\n",
    "    recall = class_report['weighted avg']['recall']\n",
    "    f1_score = class_report['weighted avg']['f1-score']\n",
    "    \n",
    "    return {\n",
    "        'Classifier': classifier.__class__.__name__,\n",
    "        'Feature Type': feature_type,\n",
    "        'Accuracy': acc_score,\n",
    "        'Balanced Accuracy': balanced_accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-score': f1_score\n",
    "    }\n",
    "\n",
    "def plot_bar_chart(accuracies_tfidf, accuracies_distilbert, accuracies_gcn, accuracies_rnn, classifiers):\n",
    "    datasets = ['Mozilla', 'Eclipse']\n",
    "    bar_width = 0.2\n",
    "    opacity = 0.8\n",
    "\n",
    "    for idx, dataset in enumerate(datasets):\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        index = np.arange(len(classifiers))\n",
    "\n",
    "        for i, classifier in enumerate(classifiers):\n",
    "            tfidf_val = accuracies_tfidf[idx][i]\n",
    "            distilbert_val = accuracies_distilbert[idx][i]\n",
    "            gcn_val = accuracies_gcn[idx][i]\n",
    "            rnn_val = accuracies_rnn[idx][i]\n",
    "\n",
    "            plt.bar(index[i], tfidf_val, bar_width,\n",
    "                    alpha=opacity,\n",
    "                    color='skyblue',\n",
    "                    label=f'{classifier} TF-IDF')\n",
    "\n",
    "            plt.bar(index[i] + bar_width, distilbert_val, bar_width,\n",
    "                    alpha=opacity,\n",
    "                    color='lightcoral',\n",
    "                    label=f'{classifier} DistilBERT')\n",
    "\n",
    "            plt.bar(index[i] + 2 * bar_width, gcn_val, bar_width,\n",
    "                    alpha=opacity,\n",
    "                    color='lightgreen',\n",
    "                    label=f'{classifier} GCN')\n",
    "\n",
    "            plt.bar(index[i] + 3 * bar_width, rnn_val, bar_width,\n",
    "                    alpha=opacity,\n",
    "                    color='gold',\n",
    "                    label=f'{classifier} RNN')\n",
    "\n",
    "            plt.text(index[i], tfidf_val + 0.02, f'{tfidf_val:.2f}', ha='center', va='bottom')\n",
    "            plt.text(index[i] + bar_width, distilbert_val + 0.02, f'{distilbert_val:.2f}', ha='center', va='bottom')\n",
    "            plt.text(index[i] + 2 * bar_width, gcn_val + 0.02, f'{gcn_val:.2f}', ha='center', va='bottom')\n",
    "            plt.text(index[i] + 3 * bar_width, rnn_val + 0.02, f'{rnn_val:.2f}', ha='center', va='bottom')\n",
    "\n",
    "        plt.xlabel('Classifiers')\n",
    "        plt.ylabel('Balanced Accuracy')\n",
    "        plt.title(f'Balanced Accuracy Comparison for {dataset} Dataset')\n",
    "        plt.xticks(index + 1.5 * bar_width, classifiers)\n",
    "        plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "        plt.tight_layout()\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "def create_summary_table(results):\n",
    "    # Initialize an empty list to collect data\n",
    "    summary_data = []\n",
    "\n",
    "    # Iterate over results and append to summary_data list\n",
    "    for result in results:\n",
    "        classifier = result['Classifier']\n",
    "        feature_type = result['Feature Type']\n",
    "        acc_score = result['Accuracy']\n",
    "        balanced_acc = result['Balanced Accuracy']\n",
    "        precision = result['Precision']\n",
    "        recall = result['Recall']\n",
    "        f1_score = result['F1-score']\n",
    "\n",
    "        summary_data.append({\n",
    "            'Classifier': classifier,\n",
    "            'Feature Type': feature_type,\n",
    "            'Accuracy': acc_score,\n",
    "            'Balanced Accuracy': balanced_acc,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1-score': f1_score\n",
    "        })\n",
    "\n",
    "    # Create DataFrame from summary_data list\n",
    "    df = pd.DataFrame(summary_data)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Load and preprocess data for different projects\n",
    "data_paths = [\n",
    "    r'C:\\Users\\hp\\Desktop\\New folder (2)\\mozilla_bug_report_data.csv',\n",
    "    r'C:\\Users\\hp\\Desktop\\New folder (2)\\eclipse_bug_report_data.csv',\n",
    "]\n",
    "\n",
    "classifiers = ['KNN', 'NB', 'NN', 'RF', 'SVM']\n",
    "\n",
    "# Initialize empty lists to collect results\n",
    "results = []\n",
    "\n",
    "for data_path in data_paths:\n",
    "    print(f'Processing data from: {data_path}')\n",
    "    bug_reports = load_and_preprocess_data(data_path)\n",
    "\n",
    "    X_tfidf = extract_tfidf_features(bug_reports)\n",
    "    X_distilbert = extract_distilbert_features(bug_reports)\n",
    "    X_gcn = extract_gcn_features(bug_reports)  # Placeholder for GCN features\n",
    "    X_rnn = extract_rnn_features(bug_reports)  # Placeholder for RNN features\n",
    "    y = bug_reports['bug_class']\n",
    "\n",
    "    # Initialize StratifiedKFold\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "    for train_index, test_index in skf.split(X_tfidf, y):\n",
    "        X_train_tfidf, X_test_tfidf = X_tfidf[train_index], X_tfidf[test_index]\n",
    "        X_train_distilbert, X_test_distilbert = X_distilbert[train_index], X_distilbert[test_index]\n",
    "        X_train_gcn, X_test_gcn = X_gcn[train_index], X_gcn[test_index]\n",
    "        X_train_rnn, X_test_rnn = X_rnn[train_index], X_rnn[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        for classifier_name in classifiers:\n",
    "            if classifier_name == 'KNN':\n",
    "                classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "            elif classifier_name == 'NB':\n",
    "                continue  # Skip MultinomialNB for DistilBERT features\n",
    "            elif classifier_name == 'NN':\n",
    "                classifier = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500)\n",
    "            elif classifier_name == 'RF':\n",
    "                classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "            elif classifier_name == 'SVM':\n",
    "                classifier = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "            # Train and evaluate classifier using TF-IDF features\n",
    "            result_tfidf = train_and_evaluate_classifier(X_train_tfidf, X_test_tfidf, y_train, y_test, classifier, 'TF-IDF')\n",
    "            results.append(result_tfidf)\n",
    "\n",
    "            # Train and evaluate classifier using DistilBERT features\n",
    "            result_distilbert = train_and_evaluate_classifier(X_train_distilbert, X_test_distilbert, y_train, y_test, classifier, 'DistilBERT')\n",
    "            results.append(result_distilbert)\n",
    "\n",
    "            # Train and evaluate classifier using GCN features\n",
    "            result_gcn = train_and_evaluate_classifier(X_train_gcn, X_test_gcn, y_train, y_test, classifier, 'GCN')\n",
    "            results.append(result_gcn)\n",
    "\n",
    "            # Train and evaluate classifier using RNN features\n",
    "            result_rnn = train_and_evaluate_classifier(X_train_rnn, X_test_rnn, y_train, y_test, classifier, 'RNN')\n",
    "            results.append(result_rnn)\n",
    "\n",
    "# Create summary table\n",
    "summary_table = create_summary_table(results)\n",
    "\n",
    "# Print or display the summary table\n",
    "print(summary_table)\n",
    "\n",
    "# Optionally, save the summary table to a CSV file\n",
    "summary_table.to_csv('classifier_comparison_summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3845159d-f67d-480d-8337-ab9acee7dace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
